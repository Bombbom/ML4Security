{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQ3ugfCGzYCb5+yMVrw1T8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bombbom/ML4Security/blob/main/Gradient_Descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mPx0sCp6Lgej"
      },
      "outputs": [],
      "source": [
        "from __future__ import division, print_function, unicode_literals\n",
        "import math\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def grad(x):\n",
        "    '''\n",
        "    để tính đạo hàm\n",
        "    '''\n",
        "    return 2*x+ 5*np.cos(x)\n",
        "\n",
        "def cost(x):\n",
        "    '''\n",
        "    để tính giá trị của hàm số. \n",
        "    Hàm này không sử dụng trong thuật toán nhưng thường được dùng để kiểm tra việc tính đạo hàm của đúng không hoặc để xem giá trị của hàm số có giảm theo mỗi vòng lặp hay không.\n",
        "    '''\n",
        "    return x**2 + 5*np.sin(x)\n",
        "\n",
        "def myGD1(eta, x0):\n",
        "    '''\n",
        "      myGD1 là phần chính thực hiện thuật toán Gradient Desent nêu phía trên. \n",
        "      Đầu vào của hàm số này là learning rate và điểm bắt đầu. \n",
        "      Thuật toán dừng lại khi đạo hàm có độ lớn đủ nhỏ.\n",
        "    '''\n",
        "    x = [x0]\n",
        "    for it in range(100):\n",
        "        x_new = x[-1] - eta*grad(x[-1])\n",
        "        if abs(grad(x_new)) < 1e-3:\n",
        "            break\n",
        "        x.append(x_new)\n",
        "    return (x, it)"
      ],
      "metadata": {
        "id": "aoLw6g8hLxE2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x1, it1) = myGD1(.1, -5)\n",
        "(x2, it2) = myGD1(.1, 5)\n",
        "print('Solution x1 = %f, cost = %f, obtained after %d iterations'%(x1[-1], cost(x1[-1]), it1))\n",
        "print('Solution x2 = %f, cost = %f, obtained after %d iterations'%(x2[-1], cost(x2[-1]), it2))"
      ],
      "metadata": {
        "id": "TfCn9g6JMQmT",
        "outputId": "44887958-e33b-4567-ffdb-691cb9eb658a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution x1 = -1.110667, cost = -3.246394, obtained after 11 iterations\n",
            "Solution x2 = -1.110341, cost = -3.246394, obtained after 29 iterations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1YjCFCIAMC5W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}