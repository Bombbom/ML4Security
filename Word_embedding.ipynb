{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPESX/XtyzUvZitGtxk2i+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bombbom/ML4Security/blob/main/Word_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeding"
      ],
      "metadata": {
        "id": "MIsnJdAz69q7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phương pháp SVD"
      ],
      "metadata": {
        "id": "bCXM8DOV7AXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install underthesea"
      ],
      "metadata": {
        "id": "_0FZY9yn7KRu",
        "outputId": "257180dd-31b8-4962-da10-3be0c881fff9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting underthesea\n",
            "  Downloading underthesea-1.3.5-py3-none-any.whl (11.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.0 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from underthesea) (2.23.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from underthesea) (6.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from underthesea) (4.64.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.0.2)\n",
            "Collecting underthesea-core==0.0.5a2\n",
            "  Downloading underthesea_core-0.0.5_alpha.2-cp37-cp37m-manylinux2010_x86_64.whl (591 kB)\n",
            "\u001b[K     |████████████████████████████████| 591 kB 55.6 MB/s \n",
            "\u001b[?25hCollecting python-crfsuite>=0.9.6\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.7)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->underthesea) (2022.6.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2022.9.24)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.7.3)\n",
            "Installing collected packages: unidecode, underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.8 underthesea-1.3.5 underthesea-core-0.0.5a2 unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.linalg as ln \n",
        "import numpy as np\n",
        "from underthesea import word_tokenize\n",
        "\n",
        "sentence = 'Khoa học dữ liệu là một lĩnh vực đòi hỏi kiến thức về toán và lập trình. Tôi rất yêu thích Khoa học dữ liệu.'\n",
        "token = word_tokenize(sentence)\n",
        "# Tokenize câu search\n",
        "print('tokenization of sentences: ', token)"
      ],
      "metadata": {
        "id": "ui7NseqV7CJA",
        "outputId": "06360d49-e1a0-439d-f300-365822e60b05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenization of sentences:  ['Khoa học', 'dữ liệu', 'là', 'một', 'lĩnh vực', 'đòi hỏi', 'kiến thức', 'về', 'toán', 'và', 'lập trình', '.', 'Tôi', 'rất', 'yêu thích', 'Khoa học', 'dữ liệu', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import coo_matrix\n",
        "# Tạo ma trận coherence dưới dạng sparse thông qua khai báo vị trí khác 0 của trục x và y\n",
        "row = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13]\n",
        "col = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14]\n",
        "data =      [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "\n",
        "X = coo_matrix((data, (row, col)), shape=(15, 15)).toarray()\n",
        "X"
      ],
      "metadata": {
        "id": "YNTfYVRE7SOO",
        "outputId": "b9aef8e1-f822-411c-ef52-74fdf4aa4b56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Thực hiện phân tích suy biến:\n",
        "U, S_diag, V = ln.svd(X)\n",
        "print('Shape of U: ', U.shape)\n",
        "print('Length of diagonal: ', len(S_diag))\n",
        "print('Shape of V: ', V.shape)"
      ],
      "metadata": {
        "id": "BO5h6yjo7YYt",
        "outputId": "1a42630e-8595-4b5e-a281-a97c135bfd22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of U:  (15, 15)\n",
            "Length of diagonal:  15\n",
            "Shape of V:  (15, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "S_truncate = np.zeros(shape = (6, 15))\n",
        "np.fill_diagonal(S_truncate, S_diag[:6])\n",
        "print('S truncate: \\n', S_truncate)\n",
        "print('Word Embedding 6 dimensionality: \\n', np.dot(S_truncate, V))\n"
      ],
      "metadata": {
        "id": "el-cPr-a7awi",
        "outputId": "e568632f-9f1d-4c55-c080-c52e6dde49e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S truncate: \n",
            " [[2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Word Embedding 6 dimensionality: \n",
            " [[0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phương pháp auto encoder"
      ],
      "metadata": {
        "id": "Zg99Oh8y7eLF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2XM12PCm7rBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mô hình word2vec"
      ],
      "metadata": {
        "id": "YqIWSKE97rYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences "
      ],
      "metadata": {
        "id": "WCNrkYAMASBW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import text\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "from nltk.corpus import gutenberg\n",
        "from string import punctuation\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "norm_bible = gutenberg.sents('bible-kjv.txt') \n",
        "norm_bible = [' '.join(doc) for doc in norm_bible]\n",
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(norm_bible)\n",
        "word2id = tokenizer.word_index\n",
        "\n",
        "# build vocabulary of unique words\n",
        "word2id['PAD'] = 0\n",
        "id2word = {v:k for k, v in word2id.items()}\n",
        "vocab_size = len(word2id)\n",
        "\n",
        "print('Vocabulary Size:', vocab_size)\n",
        "print('Vocabulary Sample:', list(word2id.items())[:10])\n"
      ],
      "metadata": {
        "id": "dudhRDPb_WaU",
        "outputId": "76d4a019-c9eb-4fe7-ca52-b87c2d359698",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 12746\n",
            "Vocabulary Sample: [('the', 1), ('and', 2), ('of', 3), ('to', 4), ('that', 5), ('in', 6), ('he', 7), ('shall', 8), ('unto', 9), ('for', 10)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in norm_bible]\n",
        "print('Embedding sentence by index: ', wids[:5])"
      ],
      "metadata": {
        "id": "Z9iYcwe-_cSe",
        "outputId": "fc31a541-abc9-42d8-dbdf-e0b904dc1b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding sentence by index:  [[1, 53, 1342, 6058], [1, 280, 2678, 3, 1, 53, 1342, 6058], [1, 254, 448, 3, 162, 194, 8769], [43, 43, 6, 1, 734, 27, 1368, 1, 205, 2, 1, 139], [43, 48, 2, 1, 139, 26, 258, 2085, 2, 2086, 2, 551, 26, 46, 1, 266, 3, 1, 1030]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
        "    context_length = window_size*2\n",
        "    for words in corpus:\n",
        "        sentence_length = len(words)\n",
        "        # print('words: ', words)\n",
        "        for index, word in enumerate(words):\n",
        "            context_words = []\n",
        "            label_word   = [] \n",
        "            # Start index of context\n",
        "            start = index - window_size\n",
        "            # End index of context\n",
        "            end = index + window_size + 1\n",
        "            # List of context_words\n",
        "            context_words.append([words[i] for i in range(start, end) if 0 <= i < sentence_length and i != index])\n",
        "            # List of label_word (also is target word).\n",
        "            # print('context words {}: {}'.format(context_words, index))\n",
        "            label_word.append(word)\n",
        "            # Padding the input 0 in the left in case it does not satisfy number of context_words = 2*window_size.\n",
        "            x = pad_sequences(context_words, maxlen=context_length)\n",
        "            # print('context words padded: ', x)\n",
        "            # Convert label_word into one-hot vector corresponding with its index\n",
        "            y = np_utils.to_categorical(label_word, vocab_size)\n",
        "            yield (x, y)\n",
        "            \n",
        "            \n",
        "# Test this out for some samples\n",
        "i = 0\n",
        "window_size = 2 # context window size\n",
        "for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
        "    if 0 not in x[0]:\n",
        "        print('Context (X):', [id2word[w] for w in x[0]], '-> Target (Y):', id2word[np.argwhere(y[0])[0][0]])\n",
        "    \n",
        "        if i == 10:\n",
        "            break\n",
        "        i += 1"
      ],
      "metadata": {
        "id": "kFDShVkyACsa",
        "outputId": "3225f2b2-97d7-4f3e-d19e-6c030e89bd14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context (X): ['the', 'old', 'of', 'the'] -> Target (Y): testament\n",
            "Context (X): ['old', 'testament', 'the', 'king'] -> Target (Y): of\n",
            "Context (X): ['testament', 'of', 'king', 'james'] -> Target (Y): the\n",
            "Context (X): ['of', 'the', 'james', 'bible'] -> Target (Y): king\n",
            "Context (X): ['the', 'first', 'of', 'moses'] -> Target (Y): book\n",
            "Context (X): ['first', 'book', 'moses', 'called'] -> Target (Y): of\n",
            "Context (X): ['book', 'of', 'called', 'genesis'] -> Target (Y): moses\n",
            "Context (X): ['1', '1', 'the', 'beginning'] -> Target (Y): in\n",
            "Context (X): ['1', 'in', 'beginning', 'god'] -> Target (Y): the\n",
            "Context (X): ['in', 'the', 'god', 'created'] -> Target (Y): beginning\n",
            "Context (X): ['the', 'beginning', 'created', 'the'] -> Target (Y): god\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Lambda\n",
        "embed_size = 100\n",
        "\n",
        "# build CBOW architecture\n",
        "cbow = Sequential()\n",
        "cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=window_size*2))\n",
        "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n",
        "cbow.add(Dense(vocab_size, activation='softmax'))\n",
        "cbow.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "# view model summary\n",
        "print(cbow.summary())"
      ],
      "metadata": {
        "id": "xfAAL446A48F",
        "outputId": "f94f99ed-86ed-4a05-c559-f0696d078e02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 4, 100)            1274600   \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 12746)             1287346   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,561,946\n",
            "Trainable params: 2,561,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('number of window: ', len(wids))"
      ],
      "metadata": {
        "id": "16Q3Fmz2A9FO",
        "outputId": "daf6bd0f-8f06-4ab9-e7b7-3e53979040d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of window:  30103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 6):\n",
        "    loss = 0.\n",
        "    i = 0\n",
        "    for x, y in generate_context_word_pairs(corpus=wids[:100], window_size=window_size, vocab_size=vocab_size):\n",
        "        i += 1\n",
        "        loss += cbow.train_on_batch(x, y)\n",
        "        if i % 500 == 0:\n",
        "            print('Processed {} (context, word) pairs'.format(i))\n",
        "\n",
        "    print('Epoch:', epoch, '\\tLoss:', loss)"
      ],
      "metadata": {
        "id": "6ujxT_TzA_5u",
        "outputId": "7930fe40-0e2c-47ed-a431-4e5edcfbf97a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 500 (context, word) pairs\n",
            "Processed 1000 (context, word) pairs\n",
            "Processed 1500 (context, word) pairs\n",
            "Processed 2000 (context, word) pairs\n",
            "Processed 2500 (context, word) pairs\n",
            "Epoch: 1 \tLoss: 20384.8660287261\n",
            "Processed 500 (context, word) pairs\n",
            "Processed 1000 (context, word) pairs\n",
            "Processed 1500 (context, word) pairs\n",
            "Processed 2000 (context, word) pairs\n",
            "Processed 2500 (context, word) pairs\n",
            "Epoch: 2 \tLoss: 17173.43113386631\n",
            "Processed 500 (context, word) pairs\n",
            "Processed 1000 (context, word) pairs\n",
            "Processed 1500 (context, word) pairs\n",
            "Processed 2000 (context, word) pairs\n",
            "Processed 2500 (context, word) pairs\n",
            "Epoch: 3 \tLoss: 16379.349256694317\n",
            "Processed 500 (context, word) pairs\n",
            "Processed 1000 (context, word) pairs\n",
            "Processed 1500 (context, word) pairs\n",
            "Processed 2000 (context, word) pairs\n",
            "Processed 2500 (context, word) pairs\n",
            "Epoch: 4 \tLoss: 15575.295589871705\n",
            "Processed 500 (context, word) pairs\n",
            "Processed 1000 (context, word) pairs\n",
            "Processed 1500 (context, word) pairs\n",
            "Processed 2000 (context, word) pairs\n",
            "Processed 2500 (context, word) pairs\n",
            "Epoch: 5 \tLoss: 15072.13867303729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "weights = cbow.get_weights()[0]\n",
        "weights = weights[1:]\n",
        "print(weights.shape)\n",
        "\n",
        "pd.DataFrame(weights, index=list(id2word.values())[1:]).head()\n"
      ],
      "metadata": {
        "id": "sgrwyWkvBGfa",
        "outputId": "10121b62-cb7a-4361-cc7c-022878cae2c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12745, 100)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6   \\\n",
              "and  -0.351118  0.543816 -0.468716  0.437784 -0.029809 -0.275138 -0.039175   \n",
              "of   -0.065142 -0.346393 -0.104054  0.729209  0.201078  0.056018  0.192336   \n",
              "to    0.209834 -0.385036  0.008873 -0.028243 -0.011523  0.057782 -0.031892   \n",
              "that -0.026888 -0.159082 -0.063215  0.050792  0.035734  0.019387  0.001664   \n",
              "in   -0.022308 -0.269732  0.007080  0.210986  0.122862 -0.049250 -0.019540   \n",
              "\n",
              "            7         8         9   ...        90        91        92  \\\n",
              "and  -0.441851 -0.392934  1.049883  ... -0.662144  0.086080  0.153858   \n",
              "of   -0.210294 -0.050321 -0.236189  ... -0.135934 -0.084429 -0.095710   \n",
              "to    0.009370  0.555452 -0.538271  ... -0.096060 -0.095967  0.056461   \n",
              "that -0.038233  0.021907 -0.155526  ... -0.088926 -0.061309 -0.089786   \n",
              "in   -0.073567 -0.084695 -0.231268  ... -0.081946  0.086392 -0.148656   \n",
              "\n",
              "            93        94        95        96        97        98        99  \n",
              "and  -0.108796 -0.056237  0.098788 -0.283321 -0.160792 -0.019008  0.014801  \n",
              "of    0.062267  0.076661  0.086354  0.045745  0.078855 -0.310600 -0.237714  \n",
              "to    0.082789 -0.084422 -0.003087  0.182432 -0.105490 -0.109812 -0.109385  \n",
              "that -0.030801  0.038394 -0.015919 -0.000981  0.092027 -0.004364 -0.094230  \n",
              "in   -0.002387 -0.014070  0.111552  0.057566  0.079728 -0.053565 -0.088998  \n",
              "\n",
              "[5 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ed8f2b4-f0cb-4c43-a7a3-74c218d50415\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>-0.351118</td>\n",
              "      <td>0.543816</td>\n",
              "      <td>-0.468716</td>\n",
              "      <td>0.437784</td>\n",
              "      <td>-0.029809</td>\n",
              "      <td>-0.275138</td>\n",
              "      <td>-0.039175</td>\n",
              "      <td>-0.441851</td>\n",
              "      <td>-0.392934</td>\n",
              "      <td>1.049883</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.662144</td>\n",
              "      <td>0.086080</td>\n",
              "      <td>0.153858</td>\n",
              "      <td>-0.108796</td>\n",
              "      <td>-0.056237</td>\n",
              "      <td>0.098788</td>\n",
              "      <td>-0.283321</td>\n",
              "      <td>-0.160792</td>\n",
              "      <td>-0.019008</td>\n",
              "      <td>0.014801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>-0.065142</td>\n",
              "      <td>-0.346393</td>\n",
              "      <td>-0.104054</td>\n",
              "      <td>0.729209</td>\n",
              "      <td>0.201078</td>\n",
              "      <td>0.056018</td>\n",
              "      <td>0.192336</td>\n",
              "      <td>-0.210294</td>\n",
              "      <td>-0.050321</td>\n",
              "      <td>-0.236189</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.135934</td>\n",
              "      <td>-0.084429</td>\n",
              "      <td>-0.095710</td>\n",
              "      <td>0.062267</td>\n",
              "      <td>0.076661</td>\n",
              "      <td>0.086354</td>\n",
              "      <td>0.045745</td>\n",
              "      <td>0.078855</td>\n",
              "      <td>-0.310600</td>\n",
              "      <td>-0.237714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.209834</td>\n",
              "      <td>-0.385036</td>\n",
              "      <td>0.008873</td>\n",
              "      <td>-0.028243</td>\n",
              "      <td>-0.011523</td>\n",
              "      <td>0.057782</td>\n",
              "      <td>-0.031892</td>\n",
              "      <td>0.009370</td>\n",
              "      <td>0.555452</td>\n",
              "      <td>-0.538271</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.096060</td>\n",
              "      <td>-0.095967</td>\n",
              "      <td>0.056461</td>\n",
              "      <td>0.082789</td>\n",
              "      <td>-0.084422</td>\n",
              "      <td>-0.003087</td>\n",
              "      <td>0.182432</td>\n",
              "      <td>-0.105490</td>\n",
              "      <td>-0.109812</td>\n",
              "      <td>-0.109385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>that</th>\n",
              "      <td>-0.026888</td>\n",
              "      <td>-0.159082</td>\n",
              "      <td>-0.063215</td>\n",
              "      <td>0.050792</td>\n",
              "      <td>0.035734</td>\n",
              "      <td>0.019387</td>\n",
              "      <td>0.001664</td>\n",
              "      <td>-0.038233</td>\n",
              "      <td>0.021907</td>\n",
              "      <td>-0.155526</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.088926</td>\n",
              "      <td>-0.061309</td>\n",
              "      <td>-0.089786</td>\n",
              "      <td>-0.030801</td>\n",
              "      <td>0.038394</td>\n",
              "      <td>-0.015919</td>\n",
              "      <td>-0.000981</td>\n",
              "      <td>0.092027</td>\n",
              "      <td>-0.004364</td>\n",
              "      <td>-0.094230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>-0.022308</td>\n",
              "      <td>-0.269732</td>\n",
              "      <td>0.007080</td>\n",
              "      <td>0.210986</td>\n",
              "      <td>0.122862</td>\n",
              "      <td>-0.049250</td>\n",
              "      <td>-0.019540</td>\n",
              "      <td>-0.073567</td>\n",
              "      <td>-0.084695</td>\n",
              "      <td>-0.231268</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.081946</td>\n",
              "      <td>0.086392</td>\n",
              "      <td>-0.148656</td>\n",
              "      <td>-0.002387</td>\n",
              "      <td>-0.014070</td>\n",
              "      <td>0.111552</td>\n",
              "      <td>0.057566</td>\n",
              "      <td>0.079728</td>\n",
              "      <td>-0.053565</td>\n",
              "      <td>-0.088998</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ed8f2b4-f0cb-4c43-a7a3-74c218d50415')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ed8f2b4-f0cb-4c43-a7a3-74c218d50415 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ed8f2b4-f0cb-4c43-a7a3-74c218d50415');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2vec with gensim \n",
        "\n"
      ],
      "metadata": {
        "id": "hejXg5rOBqmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "11AMcsYGBttn",
        "outputId": "4a6e4f76-449c-447f-c6f0-1162e4527029",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import text\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "from nltk.corpus import gutenberg\n",
        "from string import punctuation\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "norm_bible = gutenberg.sents('bible-kjv.txt') \n",
        "norm_bible = [' '.join(doc) for doc in norm_bible]"
      ],
      "metadata": {
        "id": "9VSIuFMhB22U",
        "outputId": "8c357d15-4fd4-47d7-a1de-d3488bbbdbf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "# Training model với 1000 câu đầu tiên trong kinh thánh\n",
        "sentences = [[item.lower() for item in doc.split()] for doc in norm_bible[:1000]]\n",
        "model = Word2Vec(sentences, min_count = 1, size = 150, window = 10, sg = 1, workers = 8)\n",
        "model.train(sentences, total_examples = model.corpus_count, epochs = 10)"
      ],
      "metadata": {
        "id": "B4ov52zUB4_q",
        "outputId": "aa9ab487-ba1e-4b45-d0f1-11c7c8d99a47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(209951, 336740)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy véc tơ biểu diễn của từ king\n",
        "print('embedding vector shape: ', model.wv['king'].shape)\n",
        "model.wv['king']"
      ],
      "metadata": {
        "id": "BEU4WzjSB7lg",
        "outputId": "1a711941-5718-40d3-d36e-42b0a0f6da88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding vector shape:  (150,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.05798066e-01,  1.17817692e-01, -2.96467721e-01, -2.05255039e-02,\n",
              "        4.18430209e-01,  4.09275055e-01, -1.86492443e-01,  8.83971900e-03,\n",
              "       -4.61557001e-01,  1.39143541e-01, -6.92740306e-02,  3.78509730e-01,\n",
              "        5.01622975e-01, -1.09687001e-01,  2.60338902e-01,  5.27424812e-01,\n",
              "        4.58100699e-02,  3.47823426e-02, -1.03819333e-01,  2.28391528e-01,\n",
              "        2.66170263e-01,  3.73319060e-01,  4.82162237e-01,  1.76395044e-01,\n",
              "       -3.22648704e-01, -3.39024365e-02,  3.99577796e-01, -5.24687588e-01,\n",
              "        1.03303343e-01,  2.95881957e-01,  4.41977829e-01,  6.97300360e-02,\n",
              "        9.60385660e-06, -2.45936155e-01,  5.98300338e-01,  2.52731591e-01,\n",
              "        1.79849833e-01,  2.00080797e-01, -1.28823578e-01,  2.56807506e-01,\n",
              "        1.04212455e-01,  1.04882888e-01, -3.36637527e-01,  2.70780653e-01,\n",
              "       -2.05818210e-02, -1.21858187e-01, -1.72337621e-01, -4.64683510e-02,\n",
              "       -4.30766016e-01,  4.82459255e-02, -5.34748793e-01, -2.15251908e-01,\n",
              "        4.29824851e-02,  6.53439164e-02, -9.18793865e-03, -7.39729404e-02,\n",
              "        3.51098180e-02,  3.11533779e-01,  1.03679813e-01, -2.09324867e-01,\n",
              "       -1.61752790e-01, -2.54248112e-01, -1.03363752e-01, -5.80741577e-02,\n",
              "       -1.80551019e-02,  8.82088989e-02,  1.92057386e-01, -2.19469607e-01,\n",
              "        2.21090004e-01, -2.95072436e-01,  2.68493313e-03,  3.06020826e-01,\n",
              "        9.89874750e-02, -2.49341235e-01, -4.68099415e-01, -2.27291241e-01,\n",
              "       -1.52561426e-01, -2.13708609e-01, -1.13862187e-01,  3.26464564e-01,\n",
              "        2.84878105e-01, -2.07651220e-02, -2.23736405e-01,  5.54910973e-02,\n",
              "        1.93072893e-02,  1.48076236e-01,  2.06930891e-01, -2.26742119e-01,\n",
              "        2.77078804e-02,  3.01226676e-02,  2.00475961e-01, -2.55233228e-01,\n",
              "       -8.57843608e-02, -7.33032078e-02,  7.29309618e-02,  7.51340613e-02,\n",
              "       -3.91739100e-01,  4.54959303e-01, -2.30442241e-01, -4.20324177e-01,\n",
              "       -7.34455138e-02, -5.94425380e-01, -8.04743692e-02, -3.02434891e-01,\n",
              "       -4.38438118e-01,  1.83917105e-01, -1.58036411e-01, -9.16994214e-01,\n",
              "       -2.93805718e-01,  3.09538752e-01, -3.09781253e-01,  1.08578078e-01,\n",
              "       -4.29748714e-01, -4.69589680e-02,  1.59001693e-01, -2.30293963e-02,\n",
              "       -8.11172247e-01,  2.82699108e-01, -1.66654021e-01,  1.44594580e-01,\n",
              "       -3.49574775e-01,  2.59440869e-01, -1.87070101e-01, -2.48226315e-01,\n",
              "       -2.31879845e-01,  2.29310561e-02,  8.56110096e-01,  3.20645154e-01,\n",
              "       -9.91090462e-02,  5.59508577e-02, -4.52714831e-01, -1.04732245e-01,\n",
              "        1.18845351e-01, -1.03202621e-02,  1.35330185e-01, -1.64562054e-02,\n",
              "        2.94409573e-01,  1.74027160e-01,  7.56629333e-02,  1.91470355e-01,\n",
              "       -4.03646797e-01,  3.68417129e-02,  1.12382926e-01, -7.09422529e-02,\n",
              "        1.83063775e-01, -2.35611245e-01, -2.10836247e-01, -2.20881268e-01,\n",
              "       -8.54767039e-02,  5.81677914e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar('king')"
      ],
      "metadata": {
        "id": "zdTtzhT2B-pl",
        "outputId": "4a03726f-3021-4a8f-d742-5aac1c8f911f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('admah', 0.8998588919639587),\n",
              " ('zeboiim', 0.8949166536331177),\n",
              " ('bela', 0.8677788972854614),\n",
              " ('tidal', 0.8625572919845581),\n",
              " ('shinab', 0.8561795353889465),\n",
              " ('chedorlaomer', 0.8554889559745789),\n",
              " ('shemeber', 0.8540800213813782),\n",
              " ('birsha', 0.8530709743499756),\n",
              " ('arioch', 0.8517237901687622),\n",
              " ('ellasar', 0.8476705551147461)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}